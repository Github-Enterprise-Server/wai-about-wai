---
title: "Artificial Intelligence and Accessibility Research Symposium 10 - 11 January 2023"
title_html: "Artificial Intelligence and Accessibility Research Symposium <br /> 10 - 11 January 2023"
nav_title: Symposium 2

doc-note-type: draft
doc-note-message-md: This is an unpublished draft preview that might include content that is not yet approved.

permalink: /about/projects/wai-coop/symposium2/
ref: /about/projects/wai-coop/symposium2/
lang: en
github:
  repository: w3c/wai-about-wai
  path: '_about/projects/wai-coop/symposium2.md'
  
playlist:
  - title: "First, Do No Harm: Jutta Treviranus"
    youtube-id: cRdfU-H0o6I
    default-lang: en
    captions:
      en: /about/projects/wai-coop/symposium2-captions/do_no_harm.vtt
  - title: "Natural Language Processing for Media Accessibility: Panel"
    youtube-id: 9Zub3Xs-wpw
    default-lang: en
    captions:
      en: /about/projects/wai-coop/symposium2-captions/media_accessibility.vtt
  - title: "Computer Vision for Media Accessibility: Panel"
    youtube-id: Po4q5HrMQfY
    default-lang: en
    captions:
      en: /about/projects/wai-coop/symposium2-captions/computer_vision.vtt
  - title: "Machine Learning for Web accessibility evaluation: Panel"
    youtube-id: dxV9niaotrk
    default-lang: en
    captions:
      en: /about/projects/wai-coop/symposium2-captions/machine_learning.vtt
  - title: "Natural Language Processing for Accessible Communication: Panel"
    youtube-id: YkJNOlywBZ0
    default-lang: en
    captions:
      en: /about/projects/wai-coop/symposium2-captions/accessible_communication.vtt
  - title: "Where next for assistive AI?: Shari Trewin"
    youtube-id: DICDDBHAngs
    default-lang: en
    captions:
      en: /about/projects/wai-coop/symposium2-captions/where_next.vtt
---

![An EU Project]({{ "/content-images/wai-about-wai/eu.svg" | relative_url }}){:.right.small}

{::nomarkdown}
{% include toc.html type="start" title="Page Contents" class="full" %}
{:/}

{::options toc_levels="2" /}

-   The TOC will replace this text.
{:toc}


{::nomarkdown}
{% include toc.html type="end" %}
{:/}

## Introduction
{:#introduction}

The Web Accessibility Initiative - Communities of Practice ([WAI-CooP](https://www.w3.org/WAI/about/projects/wai-coop/)) Project and the W3C Accessible Platform Architectures ([APA](https://www.w3.org/WAI/APA/)) Working Group invited researchers, practitioners, and users with disabilities to participate in an international online symposium exploring the positive and negatives impact of artificial intelligence (AI) in digital accessibility.

This online symposium brought together researchers, academics, industry, government, and people with disabilities, to explore one the most pressing emerging technologies, artificial intelligence. This symposium aimed to identify current challenges and opportunities raised by the increasing use of AI regarding digital accessibility and explore how ongoing research can leverage and hinder digital accessibility.

- Symposium date: **10 - 11 January 2023**

## Program
{:#program}

- [Opening keynote: Jutta Treviranus](#opening-keynote-jutta-treviranus)
- [Panel: Computer Vision for Media Accessibility](#panel-computer-vision-for-media-accessibility)
- [Panel: Natural Language Processing for Media Accessibility](#panel-natural-language-processing-for-media-accessibility)
- [Panel: Machine Learning for Web Accessibility Evaluation](#panel-machine-learning-for-web-accessibility-evaluation)
- [Panel: Natural Language Processing for Accessible Communication](#panel-natural-language-processing-for-accessible-communication)
- [Closing keynote: Shari Trewin](#closing-keynote-shari-trewin)

### Opening Keynote: Jutta Treviranus

**Jutta Treviranus** is the Director of the [Inclusive Design Research Centre (IDRC)](http://idrc.ocadu.ca) and professor in the faculty of Design at OCAD University in Toronto. Jutta established the IDRC in 1993 as the nexus of a growing global community that proactively works to ensure that our digitally transformed and globally connected society is designed inclusively.  Dr. Treviranus also founded an innovative graduate program in inclusive design at OCAD University.  Jutta is credited with developing an inclusive design methodology that has been adopted by large enterprise companies such as Microsoft, as well as public sector organizations internationally. In 2022 Jutta was recognized for her work in AI by [Women in AI](https://www.womeninai.co/) with the [AI for Good - DEI AI Leader of the Year award](https://www.womeninai.co/copy-of-na-media-1).

#### First, Do No Harm
In this symposium, Jutta Treviranus delivers an opening keynote that sheds light on the harms of AI specific to people with disabilities. She addresses ethical concerns surrounding AI, such as lack of representation, human bigotry, manipulative practices, unfair value extraction, exploitation, and disinformation. Jutta emphasizes the significance of considering the impact of AI on people with disabilities, as they are often at the margins of justice-deserving groups, making them more vulnerable to both existing and emerging harms. She discusses the increasing complexity of decision-making processes and the growing appeal and usefulness of AI decision tools. Jutta also highlights the challenges of data diversity, predictive accuracy, data privacy, and the need for transparency in data usage. The discussion expands to include topics such as ethics, bias, and the efforts being made globally to address AI ethics. Jutta concludes by exploring the potential of AI and the opportunity it presents to reassess what we want to automate, what we mean by concepts such as best, optimal, and fairness, and how we can include marginalized individuals in the development and use of AI technologies.


### Panel: Computer Vision for Media Accessibility

- Amy Pavel (University of Texas, US)
- Shivam Singh (mavQ, India)
- Michael Cooper (W3C, US)

This session began with panelists addressing the quality of automated image description, specifically focusing on how to define quality and train AI models to identify aspects like identity, emotion, and appearance in personal images. Different viewpoints were shared, including the recognition of emotions and specific characteristics by current systems, the importance of considering the context and user preferences, and the need for diverse training data. Responsibility and agency were also discussed, highlighting the roles of content creators and users in generating and consuming media descriptions. The impact of AI tools on user agency, the challenge of maintaining diversity in automated descriptions, and the role of the Web Accessibility Initiative (WAI) were examined. The legal and ethical issues related to AI-generated descriptions, including copyright, liability, and fair use, were explored. The potential uses of AI beyond generating alternative descriptions were considered, such as identifying functional and complex images and allowing authors to focus on those that require more attention. The challenges of explainable AI and the potential for improving augmented content were addressed, emphasizing the importance of ethics, transparency, and user understanding. Finally, the panelists discussed the value of richer alternative descriptions, the risks of errors with more detailed descriptions, and the need for a balance between concise and explanatory information.

### Panel: Natural Language Processing for Media Accessibility
- Amy Pavel (University of Texas, US)
- Shivam Singh (mavQ, India)
- Michael Cooper (W3C, US)
- Shaomei Wu (AImpower.org, US)

During the second panel of the symposium, the focus shifted to media accessibility from a natural language processing perspective. Shaomei Wu discussed the importance of accuracy and richness in these descriptions, emphasizing the need to provide more details, particularly about people. The challenge lies in sharing personal and physical attributes accurately and conscientiously. Shivam highlighted the significance of data diversity and the quality of generated data, advocating for categorizing data carefully to ensure clearer descriptions. Amy emphasized the role of context in improving description quality and suggested using language understanding and question-answering approaches. The panelists also discussed the potential of Large Language Models (LLMs) in reducing bias and emphasized the need for inclusive workflows, careful handling of social identities, and considering the trade-off between providing comprehensive information and efficiency. They addressed biases in recognition, application, and the impact of disability bias. The future perspectives included NLP for personalization, rewriting descriptions, and using NLP in academic textbooks, context sharing, augmenting media descriptions, and supporting visually impaired individuals in media creation.

### Panel: Machine Learning for Web accessibility evaluation

- Willian Massami Watanabe (Universidade Tecnológica Federal do Paraná, BR)
- Yeliz Yesilada (Middle East Technical University, TR)
- Sheng Zhou (Zhejiang University, CN)
- Fabio Paternò (CNR-IST, HIIS Laboratory, IT)

This panel featured researchers discussing web accessibility assessment and the challenges it presents. The panelists highlighted various obstacles, including the diversity and fast-changing nature of dynamic elements on web pages, the complexity of data collection and user requirements, and the subjectivity of some current evaluation rules. They emphasized the need for datasets specifically designed for accessibility and the incorporation of additional factors into the sampling process. The panelists also discussed how AI can support conformance assessment to accessibility guidelines, such as selecting representative samples and evaluating them using machine learning algorithms. AI was seen as a valuable tool for repairing accessibility issues, distinguishing complex web structures, and supporting developers in creating accessible products. The panelists envisioned future applications of machine learning techniques in web accessibility evaluation, including user interaction classification, simulating user interactions, and efficient page sampling. They emphasized the importance of scalability, automating evaluations, and generalizing approaches to integrate accessibility more easily. The development of automated testing and problem fixing, along with the availability and sharing of datasets, were seen as crucial for advancing research in AI and accessibility. Addressing bias in media accessibility was also highlighted as an important consideration for inclusive development and assessment.

### Panel: Natural Language Processing for Accessible Communication

- Chaohai Ding (University of Southampton, UK)
- Lourdes Moreno (Universidad Carlos III de Madrid, ES)
- Vikas Ashok (Old Dominion University, US)

The last panel of the symposium focused on NLP for accessible communication. The panelists discussed the challenges hindering breakthroughs in this field. Chaohai Ding highlighted the lack of data availability for AAC systems, as they require large amounts of user data and AAC data. Another challenge is the lack of data interoperability in AAC symbol sets. Cultural differences and personalization are also important considerations. Lourdes Moreno emphasized the need to address bias, particularly disability bias, in language models. She also highlighted the scarcity of datasets related to accessibility. Vikas Ashok discussed the understandability of social media content for blind individuals and the challenges of bias in natural language models. The panelists explored the issues of disability bias, accountability, and personalization in NLP tools. They discussed the importance of considering the target audience's knowledge and the need for data management. Future perspectives included the exploration of NLP metrics for accessibility, advancements in dialog systems, personalized communication, accessible modal communication, and AI assistant communication. Language simplification, data integration, and evolving apps were also mentioned as opportunities. The panelists addressed the challenge of collecting more data for accessible communication, suggesting approaches such as creating larger datasets, data repositories, and involving human experts in data generation.


### Closing Keynote: Shari Trewin

**[Dr Shari Trewin](https://www.linkedin.com/in/sharitrewin/)** is an Engineering Manager at Google, leading a team that develops new assistive technologies and features. Her background is in research, with 21 patents and 70 peer-reviewed articles including AI fairness, accessibility tools for designers and developers, web accessibility, access to virtual worlds, and self-adaptive input devices. Shari is a Distinguished Scientist of the Association of Computing Machinery (ACM), where she has chaired the ACM Special Interest Group on Accessible Computing (SIGACCESS), sat on ACM’s Diversity and Inclusion Council, and helped develop ACM’s accessibility guidance for authors and conference organizers. As Program Director of the IBM Accessibility team, she worked to elevate IBM’s product accessibility through the open source [Equal Access toolkit](https://ibm.com/able/toolkit).

#### Where next for assistive AI?

The closing keynote of the symposium by Shari Trewin focused on the digital capabilities of AI and its potential for assistive AI. Shari discussed the transformative power of AI in improving digital accessibility for people with disabilities and provided examples of how AI can contribute to this goal. She also highlighted the limitations and challenges of AI, such as biases in training data and inaccuracies in predictions. Shari emphasized the importance of research and innovation in moving digital accessibility forward with AI. She explored the concept of AI at source, where AI tools can assist content creators in generating accurate descriptions and making written content more accessible. Shari also discussed the use of AI in text-to-speech applications and the benefits of applying AI at authoring time. She highlighted the potential of AI in generating accessible code but stressed the need for training AI models on accessible code to avoid propagating past accessibility issues. Shari concluded by emphasizing the need for AI integration with authoring tools and processes to improve accessibility standards. The keynote ended with a discussion on the role of big companies in AI research, the challenges of personalization, and the importance of democratizing access to AI tools.

## Session Videos

{% include video-playlist.html %}

## Symposium Transcript
{:#transcript}

Full transcripts of the symposium are available:
- [Transcriptions of the first day](../symposium2_day1_transcript.html)
- [Transcriptions of the second day](../symposium2_day2_transcript.html)


## Conclusions and Future Directions
The symposium on AI and digital accessibility highlighted the potential of AI to enhance digital accessibility and empower stakeholders. Embedding accessibility considerations early in technology development is more than ever necessary. However, data challenges, including collection, labeling, regulation, and protection, influence disability bias in AI systems. Diversifying and reevaluating automation and acceleration is crucial. Laws and policies must be developed promptly for accountability and to address discriminatory decisions. Several opportunities rise with the emergence of Explainable AI and user involvement has the potential to promote fairness and ethical practices. AI can improve media accessibility by guiding authors and automating web accessibility evaluation. Challenges remain in accessible communication due to limited diverse data. Dialog systems offer solutions across domains. Prioritizing user and data diversity and integrating accessibility during content authoring are essential. Ethical discussions and standards are needed to ensure fair and ethical use of AI in digital accessibility.

## Organizing Committee 
{:#organizing}

### Symposium Chairs
{:#chairs}

- Carlos Duarte (LASIGE, Faculty of Sciences of the University of Lisbon)
- Letícia Seixas Pereira (LASIGE, Faculty of Sciences of the University of Lisbon)

### Scientific Committee
{:#scientific}

- Carlos Duarte (LASIGE, Faculty of Sciences of the University of Lisbon)
- Janina Sajka (Sajka Associates)
- Jason White
- Letícia Seixas Pereira (LASIGE, Faculty of Sciences of the University of Lisbon)
- Matthew Atkinson (TPGi)
- Michael Cooper (W3C)
- Scott Hollier (University of South Australia)


## Acknowledgements
{:#acknowledgements}


![An EU Project]({{ "/content-images/wai-about-wai/eu.svg" | relative_url }}){:.right.small}

This research symposium was organized by the [WAI-CooP Project](https://www.w3.org/WAI/about/projects/wai-coop/), an European Commission co-funded project, and the [W3C Accessible Platform Architectures (APA) Working Group](https://www.w3.org/WAI/APA/).
